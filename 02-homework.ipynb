{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ryicpz8mLgVq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "import heapq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMLFbhsLLgVr"
      },
      "source": [
        "In this homework, you will implement the Huffmann compression algorithm discussed in class.\n",
        "\n",
        "We are going compress Shakespear's Hamlet, so let us download the text (courtesy of Project Gutenberg).\n",
        "\n",
        "*PS: Borges' short story [The Library of Babel](https://en.wikipedia.org/wiki/The_Library_of_Babel) would be even more fitting to compress. Unfortunately it is not yet in the public domain...*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGaNQumGLgVr",
        "outputId": "165ac79e-9751-4251-8758-63d176caaa19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179096"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "URL = \"https://github.com/qi-rub/it-ss23-homework/raw/main/material/hamlet.txt\"\n",
        "hamlet = requests.get(URL).content.decode(\"ascii\", errors=\"ignore\")\n",
        "hamlet = hamlet\n",
        "len(hamlet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVTIpSJFLgVr"
      },
      "source": [
        "Thus we have around 180 KB to compress!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeLVsHjBLgVr"
      },
      "source": [
        "# Huffman Compression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6dcl2cDLgVs"
      },
      "source": [
        "Throughout this exercise, we use the following conventions:\n",
        "- **probability distributions** are represented by dictionaries that map symbols to probabilities\n",
        "- **bitstrings** are represented by Python lists or tuples that contain 0s and 1s (for simplicity)\n",
        "- **codes** are represented by dictionaries that map symbols to bitstrings\n",
        "\n",
        "The following function can be used to compute the average length of a code $C$ under a probability distribution $P$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pGYeeQuJLgVs"
      },
      "outputs": [],
      "source": [
        "def L(C, P):\n",
        "    return sum(P[x] * len(C[x]) for x in P if P[x] > 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfRFhoxiLgVs"
      },
      "source": [
        "And the following function tests if a given code is a *prefix-free* code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lwu7ZGXbLgVs"
      },
      "outputs": [],
      "source": [
        "def is_prefix_free_code(C):\n",
        "    # sort codewords by length\n",
        "    codewords = sorted(C.values(), key=len)\n",
        "\n",
        "    # check if any codeword is prefix of any other\n",
        "    for i, first in enumerate(codewords):\n",
        "        l = len(first)\n",
        "        for second in codewords[i + 1 :]:\n",
        "            if second[:l] == first:\n",
        "                return False\n",
        "    return True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKOARnkVLgVs"
      },
      "source": [
        "Here is a simple example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OJjajq9pLgVs"
      },
      "outputs": [],
      "source": [
        "P = {\"X\": 0.5, \"O\": 0.3, \"L\": 0.2}\n",
        "\n",
        "C = {\"X\": [0], \"O\": [1, 0], \"L\": [1, 1]}\n",
        "assert is_prefix_free_code(C) and L(C, P) == 1.5\n",
        "\n",
        "C = {\"X\": [0], \"O\": [0, 0], \"L\": [0, 0, 0]}\n",
        "assert not is_prefix_free_code(C) and np.round(L(C, P), 1) == 1.7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSPyrBAvLgVs"
      },
      "source": [
        "**Your first task is to implement Huffmann's algorithm.**\n",
        "\n",
        "You discussed this algorithm in class: It finds an optimal prefix-free code for a given probability distribution.\n",
        "\n",
        "Accordingly, your function should take as input a probability distribution $P$ and return as output the desired code $C$ (in the format described above)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class huffman_node:\n",
        "  def __init__(self, freq, symbol=None, left=None, right=None):\n",
        "      self.freq = freq\n",
        "      self.symbol = symbol\n",
        "      self.left = left\n",
        "      self.right = right\n",
        "      self.code = []\n",
        "\n",
        "  def __lt__(self, other):\n",
        "    return self.freq < other.freq\n",
        "\n",
        "def huffman_tree(P):\n",
        "  heap = [huffman_node(value, key) for key, value in P.items()]\n",
        "  heapq.heapify(heap)\n",
        "  while(len(heap)>1):\n",
        "    left = heapq.heappop(heap)\n",
        "    right = heapq.heappop(heap)\n",
        "    temp = huffman_node(left.freq+right.freq, None, left, right)\n",
        "    heapq.heappush(heap, temp)\n",
        "  return heap[0]\n",
        "\n",
        "def huffman_coding(node, C, code=[]):\n",
        "  if node == None:\n",
        "    return\n",
        "  if node.symbol is not None:\n",
        "    node.code.extend(code)\n",
        "    C[node.symbol] = node.code\n",
        "  else:\n",
        "    huffman_coding(node.left, C, code+[0])\n",
        "    huffman_coding(node.right, C, code+[1])\n"
      ],
      "metadata": {
        "id": "njcgmZDWMyPX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6TRa-PBjLgVs"
      },
      "outputs": [],
      "source": [
        "def huffman_code(P):\n",
        "    C = {}\n",
        "    for key in P.keys():\n",
        "      C.update({key: []})\n",
        "    h_tree = huffman_tree(P)\n",
        "    huffman_coding(h_tree, C)\n",
        "    return C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FplaIIULgVs"
      },
      "source": [
        "Here are some test cases that you can run to make sure that your code works:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5l8WgJ7JLgVs"
      },
      "outputs": [],
      "source": [
        "# the probability distribution from class\n",
        "P = {\"A\": 0.25, \"B\": 0.25, \"C\": 0.2, \"D\": 0.15, \"E\": 0.15}\n",
        "C = huffman_code(P)\n",
        "assert is_prefix_free_code(C)\n",
        "assert L(C, P) == 2.3\n",
        "\n",
        "# uniform probability distribution over a byte (8 bits)\n",
        "P = {k: 1 / 256 for k in range(256)}\n",
        "C = huffman_code(P)\n",
        "assert is_prefix_free_code(C)\n",
        "assert L(C, P) == 8\n",
        "\n",
        "# letter distribution of the English language (from MacKay's book)\n",
        "P = {\n",
        "    \"a\": 0.0575,\n",
        "    \"b\": 0.0128,\n",
        "    \"c\": 0.0263,\n",
        "    \"d\": 0.0285,\n",
        "    \"e\": 0.0913,\n",
        "    \"f\": 0.0173,\n",
        "    \"g\": 0.0133,\n",
        "    \"h\": 0.0313,\n",
        "    \"i\": 0.0599,\n",
        "    \"j\": 0.0006,\n",
        "    \"k\": 0.0084,\n",
        "    \"l\": 0.0335,\n",
        "    \"m\": 0.0235,\n",
        "    \"n\": 0.0596,\n",
        "    \"o\": 0.0689,\n",
        "    \"p\": 0.0192,\n",
        "    \"q\": 0.0008,\n",
        "    \"r\": 0.0508,\n",
        "    \"s\": 0.0567,\n",
        "    \"t\": 0.0706,\n",
        "    \"u\": 0.0334,\n",
        "    \"v\": 0.0069,\n",
        "    \"w\": 0.0119,\n",
        "    \"x\": 0.0073,\n",
        "    \"y\": 0.0164,\n",
        "    \"z\": 0.0007,\n",
        "    \" \": 0.1928,\n",
        "}\n",
        "C = huffman_code(P)\n",
        "assert is_prefix_free_code(C)\n",
        "assert np.round(L(C, P), 2) == 4.15"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dal8aJWALgVs"
      },
      "source": [
        "When compressing strings in practice, what probability distribution $P$ should we use to construct the Huffman code? A simple guess is the empirical probability distribution of the string. It is given by\n",
        "$$P(x) = \\frac {N_n} N,$$\n",
        "where $N$ is the length of the string and $N_x$ the number of times that symbol $x$ appears in it.\n",
        "\n",
        "**Write a function that takes as input a string or list of symbols and returns as output its empirical probability distribution.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "5DQGOGuHLgVs"
      },
      "outputs": [],
      "source": [
        "def empirical(s):\n",
        "    # TODO: can you implement this?\n",
        "    N=len(s)\n",
        "    Px = {}\n",
        "    for symbol in s:\n",
        "      if symbol not in Px:\n",
        "        Px.update({symbol:1/N})\n",
        "      else:\n",
        "        Px.update({symbol:Px[symbol]+1/N})\n",
        "    return Px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "b7hUq5bULgVs"
      },
      "outputs": [],
      "source": [
        "assert empirical(\"ABBBBA\") == {\"A\": 2 / 6, \"B\": 4 / 6}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH74QmPcLgVt"
      },
      "source": [
        "We are now in a good situation to compress an arbitrary unknown string.\n",
        "\n",
        "**Write a function that takes as input a string and as output returns a pair `(C,bs)`, where `C` is a Huffman code for the empirical probability distribution (as computed by `empirical`) and where `bs` is a bitstring containing the compression of the input.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "epsZLI_jLgVt"
      },
      "outputs": [],
      "source": [
        "def huffman_compress(s):\n",
        "    # TODO: can you implement this?\n",
        "    p = empirical(s)\n",
        "    C = huffman_code(p)\n",
        "    bs = []\n",
        "    for symbol in s:\n",
        "      bs.extend(C[symbol])\n",
        "    return C, bs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCm1CSBWLgVt"
      },
      "source": [
        "For your convenience, we already programmed a decompressor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jEbuflGdLgVt"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def huffman_decompress(C, bs):\n",
        "    def tree():\n",
        "        return defaultdict(tree)\n",
        "\n",
        "    # build a binary tree for \"fast\" decompression\n",
        "    root = tree()\n",
        "    for x, cw in C.items():\n",
        "        node = root\n",
        "        for b in cw[:-1]:\n",
        "            node = node[b]\n",
        "        node[cw[-1]] = x\n",
        "\n",
        "    # walk tree bit by bit\n",
        "    result = \"\"\n",
        "    node = root\n",
        "    for b in bs:\n",
        "        node = node[b]\n",
        "\n",
        "        # if we are at a leave, emit the corresponding symbol and return to root\n",
        "        if not isinstance(node, dict):\n",
        "            result += node\n",
        "            node = root\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPp6TJozLgVt"
      },
      "source": [
        "Here is a simple test to make sure that your compressor works fine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXbdRAjALgVt",
        "outputId": "83b245c3-a861-4dbb-ecf7-978151d2857a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully compressed 232 bits into 107 bits\n"
          ]
        }
      ],
      "source": [
        "PLAIN_TEXT = \"Welcome to the quantum quest.\"\n",
        "C, bs = huffman_compress(PLAIN_TEXT)\n",
        "assert huffman_decompress(C, bs) == PLAIN_TEXT\n",
        "print(f\"Successfully compressed {len(PLAIN_TEXT)*8} bits into {len(bs)} bits\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDauHMptLgVt"
      },
      "source": [
        "Of course, most savings here come from the fact that we don't use the full range of characters. What compression rate do you achieve when compressing Hamlet? Run the following code to find out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWVS5np-LgVt",
        "outputId": "e05acf36-7f66-4cc8-c78c-65b5e87bcd0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compression rate: 58%\n"
          ]
        }
      ],
      "source": [
        "# compress hamlet\n",
        "C, compressed = huffman_compress(hamlet)\n",
        "\n",
        "# make sure it decompresses correctly\n",
        "assert huffman_decompress(C, compressed) == hamlet\n",
        "\n",
        "# print compression ratio\n",
        "compressed_bytes = len(compressed) / 8\n",
        "R = compressed_bytes / len(hamlet)\n",
        "print(f\"Compression rate: {R:2.0%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kURwUDL2LgVt"
      },
      "source": [
        "# Challenge problems (completely optional)\n",
        "\n",
        "1. Download the `enwik8` data set from http://mattmahoney.net/dc/textdata.html. It contains the first 100 MB of a Wikipedia data dump. Optimize your Huffman compressor so that it can compress this data set in a few seconds! Does the decompressor need any optimizing, too?\n",
        "2. In a realistic compressor, you would return the codebook `C` as part of the bitstring `bs`. Implement this and see to which extent this impacts your compression rate."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}